{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from point_e.diffusion.configs import DIFFUSION_CONFIGS, diffusion_from_config\n",
    "from point_e.diffusion.sampler import PointCloudSampler\n",
    "from point_e.models.download import load_checkpoint\n",
    "from point_e.models.configs import MODEL_CONFIGS, model_from_config\n",
    "from point_e.util.plotting import plot_point_cloud, plot_3D\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from point_e.util.point_cloud import PointCloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\X1G6\\OneDrive - Hanoi University of Science and Technology\\FPT_AIC\\code\n",
      "^C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///C:/Users/X1G6/OneDrive%20-%20Hanoi%20University%20of%20Science%20and%20Technology/FPT_AIC/code\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: file:///C:/Users/X1G6/OneDrive%20-%20Hanoi%20University%20of%20Science%20and%20Technology/FPT_AIC/code does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating base model...\n",
      "creating upsample model...\n",
      "downloading base checkpoint...\n",
      "downloading upsampler checkpoint...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print('creating base model...')\n",
    "base_name = 'base40M-textvec'\n",
    "base_model = model_from_config(MODEL_CONFIGS[base_name], device)\n",
    "base_model.eval()\n",
    "base_diffusion = diffusion_from_config(DIFFUSION_CONFIGS[base_name])\n",
    "\n",
    "print('creating upsample model...')\n",
    "upsampler_model = model_from_config(MODEL_CONFIGS['upsample'], device)\n",
    "upsampler_model.eval()\n",
    "upsampler_diffusion = diffusion_from_config(DIFFUSION_CONFIGS['upsample'])\n",
    "\n",
    "print('downloading base checkpoint...')\n",
    "base_model.load_state_dict(load_checkpoint(base_name, device))\n",
    "\n",
    "print('downloading upsampler checkpoint...')\n",
    "upsampler_model.load_state_dict(load_checkpoint('upsample', device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = PointCloudSampler(\n",
    "    device=device,\n",
    "    models=[base_model, upsampler_model],\n",
    "    diffusions=[base_diffusion, upsampler_diffusion],\n",
    "    num_points=[1024, 4096 - 1024],\n",
    "    aux_channels=['R', 'G', 'B'],\n",
    "    guidance_scale=[3.0, 0.0],\n",
    "    model_kwargs_key_filter=('texts', ''), # Do not condition the upsampler at all\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = PointCloudSampler(\n",
    "  device=device,\n",
    "  models=[upsampler_model],\n",
    "  diffusions=[upsampler_diffusion],\n",
    "  num_points=[1024],\n",
    "  aux_channels=['R', 'G', 'B'],\n",
    "  guidance_scale=[3.0],\n",
    "  model_kwargs_key_filter=['texts'],\n",
    "  use_karras = [True],\n",
    "  karras_steps = [64],\n",
    "  sigma_min = [1e-3],\n",
    "  sigma_max = [120],\n",
    "  s_churn = [3],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.4755e-02,  8.3027e-03,  2.0180e-03,  ...,  8.1520e-03,\n",
      "          -6.8459e-02, -2.8924e-02],\n",
      "         [ 2.6321e-02,  3.2393e-02,  8.3271e-02,  ...,  4.9217e-02,\n",
      "          -4.6284e-02,  8.7147e-03],\n",
      "         [-2.3000e-01, -2.5585e-01, -1.5788e-01,  ..., -3.8034e-01,\n",
      "          -1.5378e-01, -1.7454e-01],\n",
      "         [ 1.6914e+02,  1.5722e+02,  1.4277e+02,  ...,  1.3945e+02,\n",
      "           1.6102e+02,  1.6777e+02],\n",
      "         [ 3.9010e+01,  9.5830e+00,  3.6495e+01,  ...,  4.5379e+00,\n",
      "           2.3765e+01,  2.8359e+01],\n",
      "         [-2.0927e+00,  1.1388e+01, -5.7164e+00,  ..., -2.4936e+01,\n",
      "          -3.7699e+00, -1.7856e+01]]])\n"
     ]
    }
   ],
   "source": [
    "print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5c939e94ea043a1be0313663f58231c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Produce a sample from the model.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tqdm(sampler\u001b[38;5;241m.\u001b[39msample_batch_progressive(batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, model_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(texts\u001b[38;5;241m=\u001b[39m[prompt]))):\n\u001b[0;32m      7\u001b[0m     samples \u001b[38;5;241m=\u001b[39m x\n",
      "File \u001b[1;32mc:\\Users\\X1G6\\anaconda3\\Lib\\site-packages\\tqdm\\notebook.py:254\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    253\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(tqdm_notebook, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[1;32m--> 254\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[0;32m    255\u001b[0m         \u001b[38;5;66;03m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[0;32m    256\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m    257\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\X1G6\\anaconda3\\Lib\\site-packages\\tqdm\\std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1175\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1179\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1180\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1181\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\X1G6\\OneDrive - Hanoi University of Science and Technology\\FPT_AIC\\code\\Point_E\\point_e\\diffusion\\sampler.py:163\u001b[0m, in \u001b[0;36mPointCloudSampler.sample_batch_progressive\u001b[1;34m(self, batch_size, model_kwargs, samples)\u001b[0m\n\u001b[0;32m    155\u001b[0m     samples_it \u001b[38;5;241m=\u001b[39m diffusion\u001b[38;5;241m.\u001b[39mp_sample_loop_progressive(\n\u001b[0;32m    156\u001b[0m         model,\n\u001b[0;32m    157\u001b[0m         shape\u001b[38;5;241m=\u001b[39m(internal_batch_size, \u001b[38;5;241m*\u001b[39msample_shape[\u001b[38;5;241m1\u001b[39m:]),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    160\u001b[0m         clip_denoised\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip_denoised,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m samples_it:\n\u001b[1;32m--> 163\u001b[0m     samples \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred_xstart\u001b[39m\u001b[38;5;124m\"\u001b[39m][:batch_size]\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlow_res\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m stage_model_kwargs:\n\u001b[0;32m    165\u001b[0m         samples \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[0;32m    166\u001b[0m             [stage_model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlow_res\u001b[39m\u001b[38;5;124m\"\u001b[39m][: \u001b[38;5;28mlen\u001b[39m(samples)], samples], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    167\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\X1G6\\OneDrive - Hanoi University of Science and Technology\\FPT_AIC\\code\\Point_E\\point_e\\diffusion\\k_diffusion.py:181\u001b[0m, in \u001b[0;36mkarras_sample_progressive\u001b[1;34m(diffusion, model, shape, steps, clip_denoised, progress, model_kwargs, device, sigma_min, sigma_max, rho, sampler, s_churn, s_tmin, s_tmax, s_noise, guidance_scale)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    179\u001b[0m     guided_denoiser \u001b[38;5;241m=\u001b[39m denoiser\n\u001b[1;32m--> 181\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m sample_fn(\n\u001b[0;32m    182\u001b[0m     guided_denoiser,\n\u001b[0;32m    183\u001b[0m     x_T,\n\u001b[0;32m    184\u001b[0m     sigmas,\n\u001b[0;32m    185\u001b[0m     progress\u001b[38;5;241m=\u001b[39mprogress,\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msampler_args,\n\u001b[0;32m    187\u001b[0m ):\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(diffusion, GaussianDiffusion):\n\u001b[0;32m    189\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m diffusion\u001b[38;5;241m.\u001b[39munscale_out_dict(obj)\n",
      "File \u001b[1;32mc:\\Users\\X1G6\\anaconda3\\Lib\\site-packages\\torch\\utils\\_contextlib.py:56\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m             \u001b[38;5;66;03m# Pass the last request to the generator and get its response\u001b[39;00m\n\u001b[0;32m     55\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 56\u001b[0m                 response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(request)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# We let the exceptions raised above by the generator's `.throw` or\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# `.send` methods bubble up to our caller, except for StopIteration\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;66;03m# The generator informed us that it is done: take whatever its\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;66;03m# returned value (if any) was and indicate that we're done too\u001b[39;00m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;66;03m# by returning it (see docs for python's return-statement).\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\X1G6\\OneDrive - Hanoi University of Science and Technology\\FPT_AIC\\code\\Point_E\\point_e\\diffusion\\k_diffusion.py:275\u001b[0m, in \u001b[0;36msample_heun\u001b[1;34m(denoiser, x, sigmas, progress, s_churn, s_tmin, s_tmax, s_noise)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;66;03m# Heun's method\u001b[39;00m\n\u001b[0;32m    274\u001b[0m     x_2 \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m d \u001b[38;5;241m*\u001b[39m dt\n\u001b[1;32m--> 275\u001b[0m     denoised_2 \u001b[38;5;241m=\u001b[39m denoiser(x_2, sigmas[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m s_in)\n\u001b[0;32m    276\u001b[0m     d_2 \u001b[38;5;241m=\u001b[39m to_d(x_2, sigmas[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m], denoised_2)\n\u001b[0;32m    277\u001b[0m     d_prime \u001b[38;5;241m=\u001b[39m (d \u001b[38;5;241m+\u001b[39m d_2) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\X1G6\\OneDrive - Hanoi University of Science and Technology\\FPT_AIC\\code\\Point_E\\point_e\\diffusion\\k_diffusion.py:173\u001b[0m, in \u001b[0;36mkarras_sample_progressive.<locals>.guided_denoiser\u001b[1;34m(x_t, sigma)\u001b[0m\n\u001b[0;32m    171\u001b[0m x_t \u001b[38;5;241m=\u001b[39m th\u001b[38;5;241m.\u001b[39mcat([x_t, x_t], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    172\u001b[0m sigma \u001b[38;5;241m=\u001b[39m th\u001b[38;5;241m.\u001b[39mcat([sigma, sigma], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 173\u001b[0m x_0 \u001b[38;5;241m=\u001b[39m denoiser(x_t, sigma)\n\u001b[0;32m    174\u001b[0m cond_x_0, uncond_x_0 \u001b[38;5;241m=\u001b[39m th\u001b[38;5;241m.\u001b[39msplit(x_0, \u001b[38;5;28mlen\u001b[39m(x_0) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    175\u001b[0m x_0 \u001b[38;5;241m=\u001b[39m uncond_x_0 \u001b[38;5;241m+\u001b[39m guidance_scale \u001b[38;5;241m*\u001b[39m (cond_x_0 \u001b[38;5;241m-\u001b[39m uncond_x_0)\n",
      "File \u001b[1;32mc:\\Users\\X1G6\\OneDrive - Hanoi University of Science and Technology\\FPT_AIC\\code\\Point_E\\point_e\\diffusion\\k_diffusion.py:160\u001b[0m, in \u001b[0;36mkarras_sample_progressive.<locals>.denoiser\u001b[1;34m(x_t, sigma)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdenoiser\u001b[39m(x_t, sigma):\n\u001b[1;32m--> 160\u001b[0m     _, denoised \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mdenoise(\n\u001b[0;32m    161\u001b[0m         x_t, sigma, clip_denoised\u001b[38;5;241m=\u001b[39mclip_denoised, model_kwargs\u001b[38;5;241m=\u001b[39mmodel_kwargs\n\u001b[0;32m    162\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m denoised\n",
      "File \u001b[1;32mc:\\Users\\X1G6\\OneDrive - Hanoi University of Science and Technology\\FPT_AIC\\code\\Point_E\\point_e\\diffusion\\k_diffusion.py:105\u001b[0m, in \u001b[0;36mGaussianToKarrasDenoiser.denoise\u001b[1;34m(self, x_t, sigmas, clip_denoised, model_kwargs)\u001b[0m\n\u001b[0;32m     99\u001b[0m t \u001b[38;5;241m=\u001b[39m th\u001b[38;5;241m.\u001b[39mtensor(\n\u001b[0;32m    100\u001b[0m     [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigma_to_t(sigma) \u001b[38;5;28;01mfor\u001b[39;00m sigma \u001b[38;5;129;01min\u001b[39;00m sigmas\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()],\n\u001b[0;32m    101\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mth\u001b[38;5;241m.\u001b[39mlong,\n\u001b[0;32m    102\u001b[0m     device\u001b[38;5;241m=\u001b[39msigmas\u001b[38;5;241m.\u001b[39mdevice,\n\u001b[0;32m    103\u001b[0m )\n\u001b[0;32m    104\u001b[0m c_in \u001b[38;5;241m=\u001b[39m append_dims(\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m (sigmas\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.5\u001b[39m, x_t\u001b[38;5;241m.\u001b[39mndim)\n\u001b[1;32m--> 105\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiffusion\u001b[38;5;241m.\u001b[39mp_mean_variance(\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, x_t \u001b[38;5;241m*\u001b[39m c_in, t, clip_denoised\u001b[38;5;241m=\u001b[39mclip_denoised, model_kwargs\u001b[38;5;241m=\u001b[39mmodel_kwargs\n\u001b[0;32m    107\u001b[0m )\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, out[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred_xstart\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\X1G6\\OneDrive - Hanoi University of Science and Technology\\FPT_AIC\\code\\Point_E\\point_e\\diffusion\\gaussian_diffusion.py:285\u001b[0m, in \u001b[0;36mGaussianDiffusion.p_mean_variance\u001b[1;34m(self, model, x, t, clip_denoised, denoised_fn, model_kwargs)\u001b[0m\n\u001b[0;32m    283\u001b[0m B, C \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m t\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m (B,)\n\u001b[1;32m--> 285\u001b[0m model_output \u001b[38;5;241m=\u001b[39m model(x, t, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model_output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    287\u001b[0m     model_output, extra \u001b[38;5;241m=\u001b[39m model_output\n",
      "File \u001b[1;32mc:\\Users\\X1G6\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\X1G6\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\X1G6\\OneDrive - Hanoi University of Science and Technology\\FPT_AIC\\code\\Point_E\\point_e\\models\\transformer.py:287\u001b[0m, in \u001b[0;36mCLIPImagePointDiffusionTransformer.forward\u001b[1;34m(self, x, t, images, texts, embeddings)\u001b[0m\n\u001b[0;32m    284\u001b[0m clip_embed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip_embed(clip_out)\n\u001b[0;32m    286\u001b[0m cond \u001b[38;5;241m=\u001b[39m [(clip_embed, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_cond), (t_embed, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_token_cond)]\n\u001b[1;32m--> 287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_with_cond(x, cond)\n",
      "File \u001b[1;32mc:\\Users\\X1G6\\OneDrive - Hanoi University of Science and Technology\\FPT_AIC\\code\\Point_E\\point_e\\models\\transformer.py:221\u001b[0m, in \u001b[0;36mPointDiffusionTransformer._forward_with_cond\u001b[1;34m(self, x, cond_as_token)\u001b[0m\n\u001b[0;32m    218\u001b[0m     h \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(extra_tokens \u001b[38;5;241m+\u001b[39m [h], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    220\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_pre(h)\n\u001b[1;32m--> 221\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackbone(h)\n\u001b[0;32m    222\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_post(h)\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(extra_tokens):\n",
      "File \u001b[1;32mc:\\Users\\X1G6\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\X1G6\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\X1G6\\OneDrive - Hanoi University of Science and Technology\\FPT_AIC\\code\\Point_E\\point_e\\models\\transformer.py:151\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresblocks:\n\u001b[1;32m--> 151\u001b[0m         x \u001b[38;5;241m=\u001b[39m block(x)\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\X1G6\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\X1G6\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\X1G6\\OneDrive - Hanoi University of Science and Technology\\FPT_AIC\\code\\Point_E\\point_e\\models\\transformer.py:113\u001b[0m, in \u001b[0;36mResidualAttentionBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m--> 113\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_1(x))\n\u001b[0;32m    114\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_2(x))\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\X1G6\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\X1G6\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\X1G6\\OneDrive - Hanoi University of Science and Technology\\FPT_AIC\\code\\Point_E\\point_e\\models\\transformer.py:46\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     45\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc_qkv(x)\n\u001b[1;32m---> 46\u001b[0m     x \u001b[38;5;241m=\u001b[39m checkpoint(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention, (x,), (), \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     47\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc_proj(x)\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\X1G6\\OneDrive - Hanoi University of Science and Technology\\FPT_AIC\\code\\Point_E\\point_e\\models\\checkpoint.py:27\u001b[0m, in \u001b[0;36mcheckpoint\u001b[1;34m(func, inputs, params, flag)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flag:\n\u001b[0;32m     26\u001b[0m     args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(inputs) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mtuple\u001b[39m(params)\n\u001b[1;32m---> 27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m CheckpointFunction\u001b[38;5;241m.\u001b[39mapply(func, \u001b[38;5;28mlen\u001b[39m(inputs), \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39minputs)\n",
      "File \u001b[1;32mc:\\Users\\X1G6\\anaconda3\\Lib\\site-packages\\torch\\autograd\\function.py:553\u001b[0m, in \u001b[0;36mFunction.apply\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[0;32m    551\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[0;32m    552\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[1;32m--> 553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    555\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[0;32m    556\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    557\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    558\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    559\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    560\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    561\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\X1G6\\OneDrive - Hanoi University of Science and Technology\\FPT_AIC\\code\\Point_E\\point_e\\models\\checkpoint.py:39\u001b[0m, in \u001b[0;36mCheckpointFunction.forward\u001b[1;34m(ctx, run_function, length, *args)\u001b[0m\n\u001b[0;32m     37\u001b[0m ctx\u001b[38;5;241m.\u001b[39minput_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(args[length:])\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 39\u001b[0m     output_tensors \u001b[38;5;241m=\u001b[39m ctx\u001b[38;5;241m.\u001b[39mrun_function(\u001b[38;5;241m*\u001b[39mctx\u001b[38;5;241m.\u001b[39minput_tensors)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output_tensors\n",
      "File \u001b[1;32mc:\\Users\\X1G6\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\X1G6\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\X1G6\\OneDrive - Hanoi University of Science and Technology\\FPT_AIC\\code\\Point_E\\point_e\\models\\transformer.py:83\u001b[0m, in \u001b[0;36mQKVMultiheadAttention.forward\u001b[1;34m(self, qkv)\u001b[0m\n\u001b[0;32m     79\u001b[0m weight \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39meinsum(\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbthc,bshc->bhts\u001b[39m\u001b[38;5;124m\"\u001b[39m, q \u001b[38;5;241m*\u001b[39m scale, k \u001b[38;5;241m*\u001b[39m scale\n\u001b[0;32m     81\u001b[0m )  \u001b[38;5;66;03m# More stable with f16 than dividing afterwards\u001b[39;00m\n\u001b[0;32m     82\u001b[0m wdtype \u001b[38;5;241m=\u001b[39m weight\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m---> 83\u001b[0m weight \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(weight\u001b[38;5;241m.\u001b[39mfloat(), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mtype(wdtype)\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbhts,bshc->bthc\u001b[39m\u001b[38;5;124m\"\u001b[39m, weight, v)\u001b[38;5;241m.\u001b[39mreshape(bs, n_ctx, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Set a prompt to condition on.\n",
    "prompt = 'a red motorcycle'\n",
    "\n",
    "# Produce a sample from the model.\n",
    "samples = None\n",
    "for x in tqdm(sampler.sample_batch_progressive(batch_size=1, model_kwargs=dict(texts=[prompt]))):\n",
    "    samples = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7360647b7b240de83c4306347e0c557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'low_res'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m      6\u001b[0m iterSample \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tqdm(sampler\u001b[38;5;241m.\u001b[39msample_batch_progressive(batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, model_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(texts\u001b[38;5;241m=\u001b[39m[prompt]))):\n\u001b[0;32m      8\u001b[0m   samples \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m      9\u001b[0m   iterSample\u001b[38;5;241m.\u001b[39mappend(x)\n",
      "File \u001b[1;32mc:\\Users\\X1G6\\anaconda3\\Lib\\site-packages\\tqdm\\notebook.py:254\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    253\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(tqdm_notebook, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[1;32m--> 254\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[0;32m    255\u001b[0m         \u001b[38;5;66;03m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[0;32m    256\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m    257\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\X1G6\\anaconda3\\Lib\\site-packages\\tqdm\\std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1175\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1179\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1180\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1181\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\X1G6\\OneDrive - Hanoi University of Science and Technology\\FPT_AIC\\code\\Point_E\\point_e\\diffusion\\sampler.py:130\u001b[0m, in \u001b[0;36mPointCloudSampler.sample_batch_progressive\u001b[1;34m(self, batch_size, model_kwargs, sample)\u001b[0m\n\u001b[0;32m    128\u001b[0m     stage_model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlow_res\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m samples\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcached_model_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 130\u001b[0m     stage_model_kwargs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mcached_model_kwargs(batch_size, stage_model_kwargs)\n\u001b[0;32m    131\u001b[0m sample_shape \u001b[38;5;241m=\u001b[39m (batch_size, \u001b[38;5;241m3\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maux_channels), stage_num_points)\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stage_guidance_scale \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m stage_guidance_scale \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\X1G6\\OneDrive - Hanoi University of Science and Technology\\FPT_AIC\\code\\Point_E\\point_e\\models\\transformer.py:446\u001b[0m, in \u001b[0;36mCLIPImageGridUpsamplePointDiffusionTransformer.cached_model_kwargs\u001b[1;34m(self, batch_size, model_kwargs)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m model_kwargs:\n\u001b[0;32m    442\u001b[0m     zero_emb \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\n\u001b[0;32m    443\u001b[0m         [batch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip\u001b[38;5;241m.\u001b[39mgrid_feature_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip\u001b[38;5;241m.\u001b[39mgrid_size\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m],\n\u001b[0;32m    444\u001b[0m         device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters())\u001b[38;5;241m.\u001b[39mdevice,\n\u001b[0;32m    445\u001b[0m     )\n\u001b[1;32m--> 446\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(embeddings\u001b[38;5;241m=\u001b[39mzero_emb, low_res\u001b[38;5;241m=\u001b[39mmodel_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlow_res\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    447\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m    448\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m    449\u001b[0m         embeddings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip\u001b[38;5;241m.\u001b[39membed_images_grid(model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[0;32m    450\u001b[0m         low_res\u001b[38;5;241m=\u001b[39mmodel_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlow_res\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    451\u001b[0m     )\n",
      "\u001b[1;31mKeyError\u001b[0m: 'low_res'"
     ]
    }
   ],
   "source": [
    "# Set a prompt to condition on.\n",
    "prompt = 'a dog' # @param {type:\"string\"}\n",
    "\n",
    "# Produce a sample from the model.\n",
    "samples = None\n",
    "iterSample = []\n",
    "for x in tqdm(sampler.sample_batch_progressive(batch_size=1, model_kwargs=dict(texts=[prompt]))):\n",
    "  samples = x\n",
    "  iterSample.append(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8c40b7dc3484b51a0e245b4a43c1faa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "FrozenImageCLIP.__call__() got an unexpected keyword argument 'low_res'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m      3\u001b[0m iterSample1 \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tqdm(sampler\u001b[38;5;241m.\u001b[39msample_batch_progressive(batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, model_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(texts\u001b[38;5;241m=\u001b[39m[prompt]), sample \u001b[38;5;241m=\u001b[39m iterSample[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])):\n\u001b[0;32m      5\u001b[0m   samples \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m      6\u001b[0m   iterSample1\u001b[38;5;241m.\u001b[39mappend(x)\n",
      "File \u001b[1;32mc:\\Users\\X1G6\\anaconda3\\Lib\\site-packages\\tqdm\\notebook.py:254\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    253\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(tqdm_notebook, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[1;32m--> 254\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[0;32m    255\u001b[0m         \u001b[38;5;66;03m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[0;32m    256\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m    257\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\X1G6\\anaconda3\\Lib\\site-packages\\tqdm\\std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1175\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1179\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1180\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1181\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\X1G6\\OneDrive - Hanoi University of Science and Technology\\FPT_AIC\\code\\Point_E\\point_e\\diffusion\\sampler.py:130\u001b[0m, in \u001b[0;36mPointCloudSampler.sample_batch_progressive\u001b[1;34m(self, batch_size, model_kwargs, sample)\u001b[0m\n\u001b[0;32m    128\u001b[0m     stage_model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlow_res\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m samples\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcached_model_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 130\u001b[0m     stage_model_kwargs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mcached_model_kwargs(batch_size, stage_model_kwargs)\n\u001b[0;32m    131\u001b[0m sample_shape \u001b[38;5;241m=\u001b[39m (batch_size, \u001b[38;5;241m3\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maux_channels), stage_num_points)\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stage_guidance_scale \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m stage_guidance_scale \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\X1G6\\OneDrive - Hanoi University of Science and Technology\\FPT_AIC\\code\\Point_E\\point_e\\models\\transformer.py:253\u001b[0m, in \u001b[0;36mCLIPImagePointDiffusionTransformer.cached_model_kwargs\u001b[1;34m(self, batch_size, model_kwargs)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcached_model_kwargs\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch_size: \u001b[38;5;28mint\u001b[39m, model_kwargs: Dict[\u001b[38;5;28mstr\u001b[39m, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 253\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(embeddings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip(batch_size, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs))\n",
      "\u001b[1;31mTypeError\u001b[0m: FrozenImageCLIP.__call__() got an unexpected keyword argument 'low_res'"
     ]
    }
   ],
   "source": [
    "# Produce a sample from the model.\n",
    "samples = None\n",
    "iterSample1 = []\n",
    "for x in tqdm(sampler.sample_batch_progressive(batch_size=1, model_kwargs=dict(texts=[prompt]), sample = iterSample[-1])):\n",
    "  samples = x\n",
    "  iterSample1.append(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-4.4523e-02, -1.6998e-02,  7.4959e-04,  ...,  5.8441e-03,\n",
       "          -1.2627e-02, -9.4004e-02],\n",
       "         [-5.1922e-02, -6.1807e-02, -6.6776e-02,  ..., -1.4420e-03,\n",
       "          -1.3981e-02, -2.3487e-02],\n",
       "         [-5.7757e-02, -9.6827e-03, -8.2583e-03,  ..., -1.2584e-02,\n",
       "          -3.1506e-02, -6.1024e-02],\n",
       "         [ 1.6500e+02,  1.4100e+02,  1.3700e+02,  ...,  1.3500e+02,\n",
       "           1.7500e+02,  1.9000e+02],\n",
       "         [ 9.7000e+01,  1.0500e+02,  9.4000e+01,  ...,  1.0900e+02,\n",
       "           1.1400e+02,  1.5000e+02],\n",
       "         [ 1.0100e+02,  1.1000e+02,  9.2000e+01,  ...,  1.1400e+02,\n",
       "           1.2600e+02,  1.4600e+02]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc = sampler.output_to_point_clouds(iterSample[4])[0]\n",
    "# plot_3D(pc)\n",
    "tensor = pc.to_tensor()\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<point_e.diffusion.sampler.PointCloudSampler at 0x1f520366050>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = sampler.output_to_point_clouds(samples)[0]\n",
    "fig = plot_point_cloud(pc, grid_size=3, fixed_bounds=((-0.75, -0.75, -0.75),(0.75, 0.75, 0.75)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('3.9.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b270b0f43bc427bcab7703c037711644cc480aac7c1cc8d2940cfaf0b447ee2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
